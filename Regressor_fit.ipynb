{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dim\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\Dim\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_name = r\"dataset.csv\"\n",
    "data = pd.read_csv(dataset_name, sep=';', encoding='windows-1251') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем пустые косинусные расстояния очень большими"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wr1</th>\n",
       "      <th>wr2</th>\n",
       "      <th>wr3</th>\n",
       "      <th>wr4</th>\n",
       "      <th>wr5</th>\n",
       "      <th>wr6</th>\n",
       "      <th>wr7</th>\n",
       "      <th>wr8</th>\n",
       "      <th>wblack1</th>\n",
       "      <th>wb1</th>\n",
       "      <th>...</th>\n",
       "      <th>ww3</th>\n",
       "      <th>ww4</th>\n",
       "      <th>ww5</th>\n",
       "      <th>ww6</th>\n",
       "      <th>ww7</th>\n",
       "      <th>wz1</th>\n",
       "      <th>wz2</th>\n",
       "      <th>wz3</th>\n",
       "      <th>wz4</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044504</td>\n",
       "      <td>0.060390</td>\n",
       "      <td>0.106884</td>\n",
       "      <td>0.131307</td>\n",
       "      <td>0.191969</td>\n",
       "      <td>0.196243</td>\n",
       "      <td>0.291247</td>\n",
       "      <td>0.689336</td>\n",
       "      <td>0.168612</td>\n",
       "      <td>0.083340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114733</td>\n",
       "      <td>0.120461</td>\n",
       "      <td>0.157759</td>\n",
       "      <td>0.195210</td>\n",
       "      <td>0.258014</td>\n",
       "      <td>0.196243</td>\n",
       "      <td>0.689336</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030080</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>0.078276</td>\n",
       "      <td>0.080310</td>\n",
       "      <td>0.115262</td>\n",
       "      <td>0.145493</td>\n",
       "      <td>0.463594</td>\n",
       "      <td>0.131685</td>\n",
       "      <td>0.065734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063076</td>\n",
       "      <td>0.098402</td>\n",
       "      <td>0.099977</td>\n",
       "      <td>0.147848</td>\n",
       "      <td>0.154778</td>\n",
       "      <td>0.463594</td>\n",
       "      <td>0.145493</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063378</td>\n",
       "      <td>0.077901</td>\n",
       "      <td>0.089353</td>\n",
       "      <td>0.099828</td>\n",
       "      <td>0.118236</td>\n",
       "      <td>0.143907</td>\n",
       "      <td>0.206775</td>\n",
       "      <td>0.505973</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110464</td>\n",
       "      <td>0.113365</td>\n",
       "      <td>0.167533</td>\n",
       "      <td>0.202441</td>\n",
       "      <td>0.258057</td>\n",
       "      <td>0.206775</td>\n",
       "      <td>0.505973</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.084155</td>\n",
       "      <td>0.104521</td>\n",
       "      <td>0.128896</td>\n",
       "      <td>0.149272</td>\n",
       "      <td>0.157992</td>\n",
       "      <td>0.165366</td>\n",
       "      <td>0.190774</td>\n",
       "      <td>0.299186</td>\n",
       "      <td>0.119260</td>\n",
       "      <td>0.052116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118629</td>\n",
       "      <td>0.121459</td>\n",
       "      <td>0.126427</td>\n",
       "      <td>0.135165</td>\n",
       "      <td>0.240117</td>\n",
       "      <td>0.299186</td>\n",
       "      <td>0.190774</td>\n",
       "      <td>0.165366</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060063</td>\n",
       "      <td>0.076161</td>\n",
       "      <td>0.104568</td>\n",
       "      <td>0.144232</td>\n",
       "      <td>0.166508</td>\n",
       "      <td>0.198817</td>\n",
       "      <td>0.201112</td>\n",
       "      <td>0.310254</td>\n",
       "      <td>0.126860</td>\n",
       "      <td>0.047750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096486</td>\n",
       "      <td>0.136778</td>\n",
       "      <td>0.198357</td>\n",
       "      <td>0.211746</td>\n",
       "      <td>0.292751</td>\n",
       "      <td>0.198817</td>\n",
       "      <td>0.310254</td>\n",
       "      <td>0.166508</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wr1       wr2       wr3       wr4       wr5       wr6       wr7  \\\n",
       "0  0.044504  0.060390  0.106884  0.131307  0.191969  0.196243  0.291247   \n",
       "1  0.030080  0.056448  0.062209  0.078276  0.080310  0.115262  0.145493   \n",
       "2  0.063378  0.077901  0.089353  0.099828  0.118236  0.143907  0.206775   \n",
       "3  0.084155  0.104521  0.128896  0.149272  0.157992  0.165366  0.190774   \n",
       "4  0.060063  0.076161  0.104568  0.144232  0.166508  0.198817  0.201112   \n",
       "\n",
       "        wr8   wblack1       wb1   ...         ww3       ww4       ww5  \\\n",
       "0  0.689336  0.168612  0.083340   ...    0.114733  0.120461  0.157759   \n",
       "1  0.463594  0.131685  0.065734   ...    0.063076  0.098402  0.099977   \n",
       "2  0.505973  0.089108  0.004201   ...    0.110464  0.113365  0.167533   \n",
       "3  0.299186  0.119260  0.052116   ...    0.118629  0.121459  0.126427   \n",
       "4  0.310254  0.126860  0.047750   ...    0.096486  0.136778  0.198357   \n",
       "\n",
       "        ww6       ww7       wz1       wz2        wz3   wz4    pred  \n",
       "0  0.195210  0.258014  0.196243  0.689336  10.000000  10.0  0.7500  \n",
       "1  0.147848  0.154778  0.463594  0.145493  10.000000  10.0  0.1500  \n",
       "2  0.202441  0.258057  0.206775  0.505973  10.000000  10.0  0.7500  \n",
       "3  0.135165  0.240117  0.299186  0.190774   0.165366  10.0  0.2850  \n",
       "4  0.211746  0.292751  0.198817  0.310254   0.166508  10.0  0.0855  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna(10)\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Играем за красных\n",
    "- wr1..wr8 - посорченные расстояния от красных слов до ассоциации\n",
    "- wblack1 - расстояние от чёрного слова до ассоциации\n",
    "- wb1..wb9 - посорченные расстояния от синих слов до ассоциации\n",
    "- ww1..ww7 - посорченные расстояния от синих слов до ассоциации\n",
    "- wz1..wz4 - посорченные расстояния от загаданных слов до ассоциации\n",
    "- pred - функция хорошести от угадывания игроком (w2v модель игрока)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = data.pred\n",
    "X = data.drop('pred', axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 слой - 64 нейрона с функцией активации ReLU\n",
    "- 2 слой - 128 нейронов с функцией активации ReLU\n",
    "- 3 слой - 128 нейронов с функцией активации ReLU\n",
    "- 4 слой - 64 нейрона с функцией активации ReLU\n",
    "- выходной слой - 1 выходной нейрон с функцией активации Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 130 samples, validate on 65 samples\n",
      "Epoch 1/150\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.1071 - mean_absolute_error: 0.2871 - val_loss: 0.1112 - val_mean_absolute_error: 0.3168\n",
      "Epoch 2/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.1046 - mean_absolute_error: 0.2835 - val_loss: 0.0939 - val_mean_absolute_error: 0.2895\n",
      "Epoch 3/150\n",
      "130/130 [==============================] - 23s 180ms/step - loss: 0.0995 - mean_absolute_error: 0.2960 - val_loss: 0.0895 - val_mean_absolute_error: 0.2597\n",
      "Epoch 4/150\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.1001 - mean_absolute_error: 0.2811 - val_loss: 0.1123 - val_mean_absolute_error: 0.3171\n",
      "Epoch 5/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.1008 - mean_absolute_error: 0.2907 - val_loss: 0.0886 - val_mean_absolute_error: 0.2735\n",
      "Epoch 6/150\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0939 - mean_absolute_error: 0.2865 - val_loss: 0.0907 - val_mean_absolute_error: 0.2821\n",
      "Epoch 7/150\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0942 - mean_absolute_error: 0.2835 - val_loss: 0.0903 - val_mean_absolute_error: 0.2794\n",
      "Epoch 8/150\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 0.0972 - mean_absolute_error: 0.2863 - val_loss: 0.0866 - val_mean_absolute_error: 0.2660\n",
      "Epoch 9/150\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0965 - mean_absolute_error: 0.2915 - val_loss: 0.0880 - val_mean_absolute_error: 0.2775\n",
      "Epoch 10/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0918 - mean_absolute_error: 0.2817 - val_loss: 0.0996 - val_mean_absolute_error: 0.2998\n",
      "Epoch 11/150\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0941 - mean_absolute_error: 0.2795 - val_loss: 0.0917 - val_mean_absolute_error: 0.2826\n",
      "Epoch 12/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0874 - mean_absolute_error: 0.2697 - val_loss: 0.0857 - val_mean_absolute_error: 0.2735\n",
      "Epoch 13/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0826 - mean_absolute_error: 0.2646 - val_loss: 0.0856 - val_mean_absolute_error: 0.2754\n",
      "Epoch 14/150\n",
      "130/130 [==============================] - 22s 168ms/step - loss: 0.0812 - mean_absolute_error: 0.2590 - val_loss: 0.0811 - val_mean_absolute_error: 0.2570\n",
      "Epoch 15/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0796 - mean_absolute_error: 0.2468 - val_loss: 0.0826 - val_mean_absolute_error: 0.2704\n",
      "Epoch 16/150\n",
      "130/130 [==============================] - 23s 180ms/step - loss: 0.0736 - mean_absolute_error: 0.2461 - val_loss: 0.0781 - val_mean_absolute_error: 0.2328\n",
      "Epoch 17/150\n",
      "130/130 [==============================] - 24s 188ms/step - loss: 0.0749 - mean_absolute_error: 0.2334 - val_loss: 0.0762 - val_mean_absolute_error: 0.2379\n",
      "Epoch 18/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0662 - mean_absolute_error: 0.2150 - val_loss: 0.0738 - val_mean_absolute_error: 0.2322\n",
      "Epoch 19/150\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0714 - mean_absolute_error: 0.2186 - val_loss: 0.0999 - val_mean_absolute_error: 0.2800\n",
      "Epoch 20/150\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0705 - mean_absolute_error: 0.2111 - val_loss: 0.0834 - val_mean_absolute_error: 0.2585\n",
      "Epoch 21/150\n",
      "130/130 [==============================] - 23s 180ms/step - loss: 0.0703 - mean_absolute_error: 0.2158 - val_loss: 0.0722 - val_mean_absolute_error: 0.2381\n",
      "Epoch 22/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0569 - mean_absolute_error: 0.1981 - val_loss: 0.0829 - val_mean_absolute_error: 0.2558\n",
      "Epoch 23/150\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 0.0545 - mean_absolute_error: 0.1921 - val_loss: 0.0726 - val_mean_absolute_error: 0.2116\n",
      "Epoch 24/150\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0608 - mean_absolute_error: 0.1937 - val_loss: 0.0714 - val_mean_absolute_error: 0.2270\n",
      "Epoch 25/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0539 - mean_absolute_error: 0.1833 - val_loss: 0.0713 - val_mean_absolute_error: 0.2220\n",
      "Epoch 26/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0571 - mean_absolute_error: 0.1748 - val_loss: 0.0793 - val_mean_absolute_error: 0.2061\n",
      "Epoch 27/150\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0633 - mean_absolute_error: 0.1960 - val_loss: 0.0674 - val_mean_absolute_error: 0.2155\n",
      "Epoch 28/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0562 - mean_absolute_error: 0.1861 - val_loss: 0.0746 - val_mean_absolute_error: 0.2294\n",
      "Epoch 29/150\n",
      "130/130 [==============================] - 23s 181ms/step - loss: 0.0496 - mean_absolute_error: 0.1719 - val_loss: 0.0693 - val_mean_absolute_error: 0.2190\n",
      "Epoch 30/150\n",
      "130/130 [==============================] - 23s 180ms/step - loss: 0.0450 - mean_absolute_error: 0.1656 - val_loss: 0.0743 - val_mean_absolute_error: 0.2020\n",
      "Epoch 31/150\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0565 - mean_absolute_error: 0.1781 - val_loss: 0.0821 - val_mean_absolute_error: 0.2375\n",
      "Epoch 32/150\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 0.0523 - mean_absolute_error: 0.1792 - val_loss: 0.1065 - val_mean_absolute_error: 0.2636\n",
      "Epoch 33/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0494 - mean_absolute_error: 0.1674 - val_loss: 0.0830 - val_mean_absolute_error: 0.2358\n",
      "Epoch 34/150\n",
      "130/130 [==============================] - 23s 180ms/step - loss: 0.0427 - mean_absolute_error: 0.1612 - val_loss: 0.0690 - val_mean_absolute_error: 0.2104\n",
      "Epoch 35/150\n",
      "130/130 [==============================] - 25s 189ms/step - loss: 0.0419 - mean_absolute_error: 0.1541 - val_loss: 0.0679 - val_mean_absolute_error: 0.1965\n",
      "Epoch 36/150\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0461 - mean_absolute_error: 0.1608 - val_loss: 0.0794 - val_mean_absolute_error: 0.2197\n",
      "Epoch 37/150\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0735 - mean_absolute_error: 0.1956 - val_loss: 0.0653 - val_mean_absolute_error: 0.2023\n",
      "Epoch 38/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0498 - mean_absolute_error: 0.1800 - val_loss: 0.0840 - val_mean_absolute_error: 0.2122\n",
      "Epoch 39/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0714 - mean_absolute_error: 0.1974 - val_loss: 0.0673 - val_mean_absolute_error: 0.2148\n",
      "Epoch 40/150\n",
      "130/130 [==============================] - 23s 173ms/step - loss: 0.0482 - mean_absolute_error: 0.1748 - val_loss: 0.0685 - val_mean_absolute_error: 0.2235\n",
      "Epoch 41/150\n",
      "130/130 [==============================] - 23s 173ms/step - loss: 0.0458 - mean_absolute_error: 0.1640 - val_loss: 0.0640 - val_mean_absolute_error: 0.2017\n",
      "Epoch 42/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0395 - mean_absolute_error: 0.1519 - val_loss: 0.0707 - val_mean_absolute_error: 0.2086\n",
      "Epoch 43/150\n",
      "130/130 [==============================] - 23s 173ms/step - loss: 0.0383 - mean_absolute_error: 0.1433 - val_loss: 0.0895 - val_mean_absolute_error: 0.2297\n",
      "Epoch 44/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0476 - mean_absolute_error: 0.1614 - val_loss: 0.0659 - val_mean_absolute_error: 0.2031\n",
      "Epoch 45/150\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0392 - mean_absolute_error: 0.1480 - val_loss: 0.0691 - val_mean_absolute_error: 0.2006\n",
      "Epoch 46/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0341 - mean_absolute_error: 0.1322 - val_loss: 0.0747 - val_mean_absolute_error: 0.2099\n",
      "Epoch 47/150\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0372 - mean_absolute_error: 0.1395 - val_loss: 0.0696 - val_mean_absolute_error: 0.1999\n",
      "Epoch 48/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0342 - mean_absolute_error: 0.1364 - val_loss: 0.0701 - val_mean_absolute_error: 0.1979\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0337 - mean_absolute_error: 0.1300 - val_loss: 0.0652 - val_mean_absolute_error: 0.1874\n",
      "Epoch 50/150\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0378 - mean_absolute_error: 0.1360 - val_loss: 0.0737 - val_mean_absolute_error: 0.2044\n",
      "Epoch 51/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0392 - mean_absolute_error: 0.1424 - val_loss: 0.0659 - val_mean_absolute_error: 0.1966\n",
      "Epoch 52/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0313 - mean_absolute_error: 0.1225 - val_loss: 0.0658 - val_mean_absolute_error: 0.1927\n",
      "Epoch 53/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0329 - mean_absolute_error: 0.1274 - val_loss: 0.0838 - val_mean_absolute_error: 0.2148\n",
      "Epoch 54/150\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0386 - mean_absolute_error: 0.1307 - val_loss: 0.0778 - val_mean_absolute_error: 0.2173\n",
      "Epoch 55/150\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0441 - mean_absolute_error: 0.1494 - val_loss: 0.0733 - val_mean_absolute_error: 0.2049\n",
      "Epoch 56/150\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0331 - mean_absolute_error: 0.1310 - val_loss: 0.0716 - val_mean_absolute_error: 0.1990\n",
      "Epoch 57/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0379 - mean_absolute_error: 0.1373 - val_loss: 0.0724 - val_mean_absolute_error: 0.2057\n",
      "Epoch 58/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0356 - mean_absolute_error: 0.1342 - val_loss: 0.0633 - val_mean_absolute_error: 0.1892\n",
      "Epoch 59/150\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0395 - mean_absolute_error: 0.1356 - val_loss: 0.0699 - val_mean_absolute_error: 0.1994\n",
      "Epoch 60/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0365 - mean_absolute_error: 0.1353 - val_loss: 0.0646 - val_mean_absolute_error: 0.1872\n",
      "Epoch 61/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0434 - mean_absolute_error: 0.1483 - val_loss: 0.0659 - val_mean_absolute_error: 0.1969\n",
      "Epoch 62/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0349 - mean_absolute_error: 0.1349 - val_loss: 0.0699 - val_mean_absolute_error: 0.2013\n",
      "Epoch 63/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0344 - mean_absolute_error: 0.1276 - val_loss: 0.0844 - val_mean_absolute_error: 0.2159\n",
      "Epoch 64/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0325 - mean_absolute_error: 0.1199 - val_loss: 0.0765 - val_mean_absolute_error: 0.2063\n",
      "Epoch 65/150\n",
      "130/130 [==============================] - 23s 173ms/step - loss: 0.0313 - mean_absolute_error: 0.1248 - val_loss: 0.0733 - val_mean_absolute_error: 0.2025\n",
      "Epoch 66/150\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0290 - mean_absolute_error: 0.1178 - val_loss: 0.0725 - val_mean_absolute_error: 0.1975\n",
      "Epoch 67/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0368 - mean_absolute_error: 0.1325 - val_loss: 0.0668 - val_mean_absolute_error: 0.1945\n",
      "Epoch 68/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0341 - mean_absolute_error: 0.1280 - val_loss: 0.0658 - val_mean_absolute_error: 0.1929\n",
      "Epoch 69/150\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0338 - mean_absolute_error: 0.1232 - val_loss: 0.0630 - val_mean_absolute_error: 0.1887\n",
      "Epoch 70/150\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0314 - mean_absolute_error: 0.1239 - val_loss: 0.0743 - val_mean_absolute_error: 0.2017\n",
      "Epoch 71/150\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0293 - mean_absolute_error: 0.1159 - val_loss: 0.0736 - val_mean_absolute_error: 0.1982\n",
      "Epoch 72/150\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0307 - mean_absolute_error: 0.1164 - val_loss: 0.0711 - val_mean_absolute_error: 0.1947\n",
      "Epoch 73/150\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0276 - mean_absolute_error: 0.1126 - val_loss: 0.0880 - val_mean_absolute_error: 0.2100\n",
      "Epoch 74/150\n",
      "130/130 [==============================] - 25s 191ms/step - loss: 0.0298 - mean_absolute_error: 0.1137 - val_loss: 0.0743 - val_mean_absolute_error: 0.1969\n",
      "Epoch 75/150\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0314 - mean_absolute_error: 0.1159 - val_loss: 0.0740 - val_mean_absolute_error: 0.1954\n",
      "Epoch 76/150\n",
      "130/130 [==============================] - 26s 196ms/step - loss: 0.0282 - mean_absolute_error: 0.1098 - val_loss: 0.0973 - val_mean_absolute_error: 0.2201\n",
      "Epoch 77/150\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0330 - mean_absolute_error: 0.1212 - val_loss: 0.0851 - val_mean_absolute_error: 0.2085\n",
      "Epoch 78/150\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0304 - mean_absolute_error: 0.1195 - val_loss: 0.0807 - val_mean_absolute_error: 0.2042\n",
      "Epoch 79/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0293 - mean_absolute_error: 0.1124 - val_loss: 0.0887 - val_mean_absolute_error: 0.2097\n",
      "Epoch 80/150\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 0.0334 - mean_absolute_error: 0.1221 - val_loss: 0.0710 - val_mean_absolute_error: 0.1892\n",
      "Epoch 81/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0263 - mean_absolute_error: 0.1054 - val_loss: 0.0723 - val_mean_absolute_error: 0.1934\n",
      "Epoch 82/150\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0281 - mean_absolute_error: 0.1089 - val_loss: 0.0687 - val_mean_absolute_error: 0.1869\n",
      "Epoch 83/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0299 - mean_absolute_error: 0.1090 - val_loss: 0.0654 - val_mean_absolute_error: 0.1875\n",
      "Epoch 84/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0295 - mean_absolute_error: 0.1162 - val_loss: 0.0754 - val_mean_absolute_error: 0.1988\n",
      "Epoch 85/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0273 - mean_absolute_error: 0.1074 - val_loss: 0.0683 - val_mean_absolute_error: 0.1871\n",
      "Epoch 86/150\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0338 - mean_absolute_error: 0.1184 - val_loss: 0.0659 - val_mean_absolute_error: 0.1878\n",
      "Epoch 87/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0354 - mean_absolute_error: 0.1272 - val_loss: 0.0653 - val_mean_absolute_error: 0.1887\n",
      "Epoch 88/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0332 - mean_absolute_error: 0.1209 - val_loss: 0.0720 - val_mean_absolute_error: 0.1981\n",
      "Epoch 89/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0315 - mean_absolute_error: 0.1161 - val_loss: 0.0676 - val_mean_absolute_error: 0.1887\n",
      "Epoch 90/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0270 - mean_absolute_error: 0.1094 - val_loss: 0.0761 - val_mean_absolute_error: 0.1967\n",
      "Epoch 91/150\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0268 - mean_absolute_error: 0.1051 - val_loss: 0.0752 - val_mean_absolute_error: 0.1959\n",
      "Epoch 92/150\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0263 - mean_absolute_error: 0.1052 - val_loss: 0.0732 - val_mean_absolute_error: 0.1917\n",
      "Epoch 93/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0287 - mean_absolute_error: 0.1079 - val_loss: 0.0806 - val_mean_absolute_error: 0.2006\n",
      "Epoch 94/150\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0289 - mean_absolute_error: 0.1053 - val_loss: 0.0711 - val_mean_absolute_error: 0.1912\n",
      "Epoch 95/150\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0261 - mean_absolute_error: 0.1058 - val_loss: 0.0660 - val_mean_absolute_error: 0.1850\n",
      "Epoch 96/150\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0266 - mean_absolute_error: 0.1043 - val_loss: 0.0768 - val_mean_absolute_error: 0.1956\n",
      "Epoch 97/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 22s 169ms/step - loss: 0.0268 - mean_absolute_error: 0.1039 - val_loss: 0.0853 - val_mean_absolute_error: 0.2070\n",
      "Epoch 98/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0251 - mean_absolute_error: 0.1034 - val_loss: 0.0983 - val_mean_absolute_error: 0.2207\n",
      "Epoch 99/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0380 - mean_absolute_error: 0.1267 - val_loss: 0.0833 - val_mean_absolute_error: 0.2109\n",
      "Epoch 100/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0326 - mean_absolute_error: 0.1255 - val_loss: 0.0748 - val_mean_absolute_error: 0.1988\n",
      "Epoch 101/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0257 - mean_absolute_error: 0.1018 - val_loss: 0.0708 - val_mean_absolute_error: 0.1898\n",
      "Epoch 102/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0267 - mean_absolute_error: 0.1038 - val_loss: 0.0745 - val_mean_absolute_error: 0.1930\n",
      "Epoch 103/150\n",
      "130/130 [==============================] - 22s 169ms/step - loss: 0.0260 - mean_absolute_error: 0.1024 - val_loss: 0.0779 - val_mean_absolute_error: 0.1971\n",
      "Epoch 104/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0359 - mean_absolute_error: 0.1152 - val_loss: 0.0677 - val_mean_absolute_error: 0.1857\n",
      "Epoch 105/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0399 - mean_absolute_error: 0.1361 - val_loss: 0.0724 - val_mean_absolute_error: 0.1965\n",
      "Epoch 106/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0417 - mean_absolute_error: 0.1434 - val_loss: 0.0713 - val_mean_absolute_error: 0.2076\n",
      "Epoch 107/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0455 - mean_absolute_error: 0.1587 - val_loss: 0.0761 - val_mean_absolute_error: 0.2153\n",
      "Epoch 108/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0345 - mean_absolute_error: 0.1313 - val_loss: 0.0740 - val_mean_absolute_error: 0.2000\n",
      "Epoch 109/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0254 - mean_absolute_error: 0.1090 - val_loss: 0.0685 - val_mean_absolute_error: 0.1860\n",
      "Epoch 110/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0307 - mean_absolute_error: 0.1152 - val_loss: 0.0645 - val_mean_absolute_error: 0.1827\n",
      "Epoch 111/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0283 - mean_absolute_error: 0.1119 - val_loss: 0.0716 - val_mean_absolute_error: 0.1919\n",
      "Epoch 112/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0287 - mean_absolute_error: 0.1073 - val_loss: 0.0769 - val_mean_absolute_error: 0.1939\n",
      "Epoch 113/150\n",
      "130/130 [==============================] - 23s 173ms/step - loss: 0.0263 - mean_absolute_error: 0.1035 - val_loss: 0.0823 - val_mean_absolute_error: 0.2025\n",
      "Epoch 114/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0272 - mean_absolute_error: 0.1099 - val_loss: 0.0899 - val_mean_absolute_error: 0.2103\n",
      "Epoch 115/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0286 - mean_absolute_error: 0.1102 - val_loss: 0.0667 - val_mean_absolute_error: 0.1870\n",
      "Epoch 116/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0236 - mean_absolute_error: 0.0996 - val_loss: 0.0802 - val_mean_absolute_error: 0.2044\n",
      "Epoch 117/150\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0291 - mean_absolute_error: 0.1094 - val_loss: 0.0776 - val_mean_absolute_error: 0.1974\n",
      "Epoch 118/150\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0280 - mean_absolute_error: 0.1112 - val_loss: 0.0696 - val_mean_absolute_error: 0.1956\n",
      "Epoch 119/150\n",
      "130/130 [==============================] - 23s 180ms/step - loss: 0.0262 - mean_absolute_error: 0.1048 - val_loss: 0.0757 - val_mean_absolute_error: 0.1913\n",
      "Epoch 120/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0248 - mean_absolute_error: 0.0981 - val_loss: 0.0689 - val_mean_absolute_error: 0.1897\n",
      "Epoch 121/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0230 - mean_absolute_error: 0.0968 - val_loss: 0.0716 - val_mean_absolute_error: 0.1921\n",
      "Epoch 122/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0241 - mean_absolute_error: 0.0952 - val_loss: 0.0695 - val_mean_absolute_error: 0.1867\n",
      "Epoch 123/150\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0228 - mean_absolute_error: 0.0948 - val_loss: 0.0663 - val_mean_absolute_error: 0.1832\n",
      "Epoch 124/150\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0235 - mean_absolute_error: 0.0944 - val_loss: 0.0752 - val_mean_absolute_error: 0.1930\n",
      "Epoch 125/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0237 - mean_absolute_error: 0.0918 - val_loss: 0.0774 - val_mean_absolute_error: 0.1984\n",
      "Epoch 126/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0242 - mean_absolute_error: 0.0991 - val_loss: 0.0747 - val_mean_absolute_error: 0.1965\n",
      "Epoch 127/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0279 - mean_absolute_error: 0.1070 - val_loss: 0.0676 - val_mean_absolute_error: 0.1824\n",
      "Epoch 128/150\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0380 - mean_absolute_error: 0.1184 - val_loss: 0.0778 - val_mean_absolute_error: 0.1986\n",
      "Epoch 129/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0446 - mean_absolute_error: 0.1533 - val_loss: 0.0885 - val_mean_absolute_error: 0.2180\n",
      "Epoch 130/150\n",
      "130/130 [==============================] - 22s 169ms/step - loss: 0.0280 - mean_absolute_error: 0.1128 - val_loss: 0.0822 - val_mean_absolute_error: 0.1999\n",
      "Epoch 131/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0269 - mean_absolute_error: 0.1087 - val_loss: 0.0718 - val_mean_absolute_error: 0.1880\n",
      "Epoch 132/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0278 - mean_absolute_error: 0.1091 - val_loss: 0.0719 - val_mean_absolute_error: 0.1897\n",
      "Epoch 133/150\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0274 - mean_absolute_error: 0.1069 - val_loss: 0.0754 - val_mean_absolute_error: 0.2015\n",
      "Epoch 134/150\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0251 - mean_absolute_error: 0.0996 - val_loss: 0.0722 - val_mean_absolute_error: 0.1924\n",
      "Epoch 135/150\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0349 - mean_absolute_error: 0.1205 - val_loss: 0.0620 - val_mean_absolute_error: 0.1823\n",
      "Epoch 136/150\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0362 - mean_absolute_error: 0.1317 - val_loss: 0.0648 - val_mean_absolute_error: 0.1905\n",
      "Epoch 137/150\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0237 - mean_absolute_error: 0.1025 - val_loss: 0.0713 - val_mean_absolute_error: 0.1884\n",
      "Epoch 138/150\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0216 - mean_absolute_error: 0.0898 - val_loss: 0.0832 - val_mean_absolute_error: 0.2024\n",
      "Epoch 139/150\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0249 - mean_absolute_error: 0.0982 - val_loss: 0.0670 - val_mean_absolute_error: 0.1890\n",
      "Epoch 140/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0209 - mean_absolute_error: 0.0897 - val_loss: 0.0735 - val_mean_absolute_error: 0.1900\n",
      "Epoch 141/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0233 - mean_absolute_error: 0.0930 - val_loss: 0.0817 - val_mean_absolute_error: 0.1989\n",
      "Epoch 142/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0386 - mean_absolute_error: 0.1292 - val_loss: 0.0606 - val_mean_absolute_error: 0.1824\n",
      "Epoch 143/150\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0308 - mean_absolute_error: 0.1175 - val_loss: 0.0641 - val_mean_absolute_error: 0.1786\n",
      "Epoch 144/150\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0284 - mean_absolute_error: 0.1067 - val_loss: 0.0703 - val_mean_absolute_error: 0.1847\n",
      "Epoch 145/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0300 - mean_absolute_error: 0.1122 - val_loss: 0.0595 - val_mean_absolute_error: 0.1740\n",
      "Epoch 146/150\n",
      "130/130 [==============================] - 22s 169ms/step - loss: 0.0280 - mean_absolute_error: 0.1116 - val_loss: 0.0735 - val_mean_absolute_error: 0.1980\n",
      "Epoch 147/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0229 - mean_absolute_error: 0.1000 - val_loss: 0.0814 - val_mean_absolute_error: 0.2026\n",
      "Epoch 148/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0213 - mean_absolute_error: 0.0904 - val_loss: 0.0685 - val_mean_absolute_error: 0.1813\n",
      "Epoch 149/150\n",
      "130/130 [==============================] - 22s 169ms/step - loss: 0.0256 - mean_absolute_error: 0.0952 - val_loss: 0.0859 - val_mean_absolute_error: 0.2020\n",
      "Epoch 150/150\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0241 - mean_absolute_error: 0.0954 - val_loss: 0.0696 - val_mean_absolute_error: 0.1919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a57201b00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 7\n",
    "# split into 67% for train and 33% for test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=29, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "# Fit the model\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23152286890039797"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "r2_score(np.array(y_test), np.array(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть модель с r2_score 0.35162464164779983 (обучена ранее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model2 = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35162467539065567"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "r2_score(np.array(y_test), np.array(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
